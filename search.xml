<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hadoop的安装(Ubantu、伪分布式)</title>
      <link href="posts/7584.html"/>
      <url>posts/7584.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>这里要特别感谢ysgg大佬分享他的踩坑记录，感谢他！</p></blockquote><h2 id="一、下载jdk配置环境变量"><a href="#一、下载jdk配置环境变量" class="headerlink" title="一、下载jdk配置环境变量"></a>一、下载jdk配置环境变量</h2><h3 id="1-下载jdk"><a href="#1-下载jdk" class="headerlink" title="1. 下载jdk"></a>1. 下载jdk</h3><p>官网下载jdk，<a href="https://www.oracle.com/cn/java/technologies/javase-downloads.html">传送门</a></p><p>这里使用的是jdk11</p><h3 id="2-配置环变量"><a href="#2-配置环变量" class="headerlink" title="2. 配置环变量"></a>2. 配置环变量</h3><p>个人为了不影响本用户，这里新创建一个<code>hadoop</code>用户，==后面所有操作均在hadoop用下完成，包括文件的用户和组均为hadoop==</p><p>将环变量配置到<code>/home/hadoop/.bashrc</code></p><p><code>.bashrc</code>是用户环境变量，<code>/etc/profile</code>是全局环境变量</p><pre class="line-numbers language-bash"><code class="language-bash">vim /home/hadoop/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下</p><pre><code>export JAVA_HOME=xxx #这里我是/usr/local/jdk11export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH</code></pre><h2 id="二、下载软件包并安装"><a href="#二、下载软件包并安装" class="headerlink" title="二、下载软件包并安装"></a>二、下载软件包并安装</h2><p>去官网下载，<a href="https://hadoop.apache.org/releases.html">传送门</a>。</p><p>这里使用的是<code>hadoop3.3.0</code></p><p>下载之后解压，将解压后的内容移动到<code>/usr/local</code>下</p><p>并重命名为<code>hadoop</code>（可选）</p><h2 id="三、安装ssh-设置无密码登陆"><a href="#三、安装ssh-设置无密码登陆" class="headerlink" title="三、安装ssh 设置无密码登陆"></a>三、安装ssh 设置无密码登陆</h2><blockquote><p>对于Hadoop的伪分布式和全分布式而言，hadoop名称节点需要启动集群中所有机器的hadoop守护进程，这个过程可通过ssh登录来实现。</p></blockquote><p>安装ssh serer,并启动服务</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> apt <span class="token function">install</span> openssh-server       <span class="token comment" spellcheck="true">#安装SSH server</span>$ <span class="token function">ps</span> -e <span class="token operator">|</span> <span class="token function">grep</span> <span class="token function">ssh</span>                      <span class="token comment" spellcheck="true">#可以看到进程sshd或者使用命令：ssh -V， 查看ssh版本</span>$ <span class="token function">sudo</span> <span class="token function">service</span> <span class="token function">ssh</span> start<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>尝试登陆看是否成功，此时要输入密码，后面配置好ssh免密登录后即可不需要输入密码</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">ssh</span> localhost                         <span class="token comment" spellcheck="true">#登陆SSH，第一次登陆输入yes</span>$ <span class="token keyword">exit</span>                                  <span class="token comment" spellcheck="true">#退出登录的ssh localhost</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>开始配置免密登录</p><p>配置sshd_config</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">cd</span> /etc/ssh$ <span class="token function">sudo</span> vim sshd_config<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>替换以下内容</p><pre><code># $OpenBSD: sshd_config,v 2.93 2014/01/10 05:59:19 djm Exp $# This is the sshd server system-wide configuration file.  See# sshd_config(5) for more information.# This sshd was compiled with PATH=/usr/local/bin:/usr/bin# The strategy used for options in the default sshd_config shipped with# OpenSSH is to specify options with their default value where# possible, but leave them commented.  Uncommented options override the# default value.# If you want to change the port on a SELinux system, you have to tell# SELinux about this change.# semanage port -a -t ssh_port_t -p tcp #PORTNUMBER##Port 22#AddressFamily any#ListenAddress 0.0.0.0#ListenAddress ::# The default requires explicit activation of protocol 1#Protocol 2# HostKey for protocol version 1#HostKey /etc/ssh/ssh_host_key# HostKeys for protocol version 2HostKey /etc/ssh/ssh_host_rsa_keyHostKey /etc/ssh/ssh_host_dsa_key#HostKey /etc/ssh/ssh_host_dsa_key#HostKey /etc/ssh/ssh_host_ecdsa_key#HostKey /etc/ssh/ssh_host_ed25519_key# Lifetime and size of ephemeral version 1 server key#KeyRegenerationInterval 1h#ServerKeyBits 1024# Ciphers and keying#RekeyLimit default none#ServerKeyBits 1024# Ciphers and keying#RekeyLimit default none# Logging# obsoletes QuietMode and FascistLogging#SyslogFacility AUTHSyslogFacility AUTHPRIV#LogLevel INFO# Authentication:#LoginGraceTime 2mPermitRootLogin yes#StrictModes yes#MaxAuthTries 6#MaxSessions 10RSAAuthentication yesPubkeyAuthentication yes# The default is to check both .ssh/authorized_keys and .ssh/authorized_keys2# but this is overridden so installations will only check .ssh/authorized_keysAuthorizedKeysFile      .ssh/authorized_keys#AuthorizedPrincipalsFile none#AuthorizedKeysCommand none#AuthorizedKeysCommandUser nobody# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts#RhostsRSAAuthentication no# similar for protocol version 2#HostbasedAuthentication no# Change to yes if you don&#39;t trust ~/.ssh/known_hosts for# RhostsRSAAuthentication and HostbasedAuthentication#IgnoreUserKnownHosts no# Don&#39;t read the user&#39;s ~/.rhosts and ~/.shosts files#IgnoreRhosts yes# To disable tunneled clear text passwords, change to no here!#PasswordAuthentication yes#PermitEmptyPasswords no# Change to no to disable s/key passwords#ChallengeResponseAuthentication yesChallengeResponseAuthentication no# Kerberos options#KerberosAuthentication no#KerberosOrLocalPasswd yes#KerberosTicketCleanup yes#KerberosGetAFSToken no#KerberosUseKuserok yes# GSSAPI optionsGSSAPIAuthentication noGSSAPICleanupCredentials no#GSSAPIStrictAcceptorCheck yes#GSSAPIKeyExchange no#GSSAPIEnablek5users no# Set this to &#39;yes&#39; to enable PAM authentication, account processing,# and session processing. If this is enabled, PAM authentication will# be allowed through the ChallengeResponseAuthentication and# PasswordAuthentication.  Depending on your PAM configuration,# PAM authentication via ChallengeResponseAuthentication may bypass# the setting of &quot;PermitRootLogin without-password&quot;.# If you just want the PAM account and session checks to run without# PAM authentication, then enable this but set PasswordAuthentication# and ChallengeResponseAuthentication to &#39;no&#39;.# WARNING: &#39;UsePAM no&#39; is not supported in Red Hat Enterprise Linux and may cause several# problems.UsePAM yes#AllowAgentForwarding yes#AllowTcpForwarding yes#GatewayPorts noX11Forwarding yes#X11DisplayOffset 10#X11UseLocalhost yes#PermitTTY yes#PrintMotd yes#PrintLastLog yes#TCPKeepAlive yes#UseLogin no#UsePrivilegeSeparation yes          # Default for new installations.#PermitUserEnvironment no#Compression delayed#ClientAliveInterval 0#ClientAliveCountMax 3#ShowPatchLevel noUseDNS no#PidFile /var/run/sshd.pid#MaxStartups 10:30:100#PermitTunnel no#ChrootDirectory none#VersionAddendum none# no default banner path#Banner none# Accept locale-related environment variablesAcceptEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGESAcceptEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENTAcceptEnv LC_IDENTIFICATION LC_ALL LANGUAGEAcceptEnv XMODIFIERS# override default of no subsystemsSubsystem       sftp    /usr/libexec/openssh/sftp-server# Example of overriding settings on a per-user basis#Match User anoncvs#       X11Forwarding no#       AllowTcpForwarding no#       PermitTTY no#       ForceCommand cvs server</code></pre><p>ssh设置免密码登陆</p><pre><code>$ cd ~/.ssh/ #如果没法进入该目录，执行一次ssh localhost$ ssh-keygen -t rsa #生成密钥对$ ssh-keygen -t dsa$ cat id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys$ cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys #设置免密登陆</code></pre><p>再次登录即可不需要密码</p><blockquote><p>此步如果出现know_host错误可以尝试将当前文件中的know_host文件删除</p></blockquote><h2 id="四、单机安装hadoop"><a href="#四、单机安装hadoop" class="headerlink" title="四、单机安装hadoop"></a>四、单机安装hadoop</h2><h3 id="1-配置环境变量"><a href="#1-配置环境变量" class="headerlink" title="1. 配置环境变量"></a>1. 配置环境变量</h3><p>类似配置jdk，加上</p><pre><code>export HADOOP_HOME=/usr/local/hadoopexport CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATHexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbinexport HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_COMMON_LIB_NATIVE_DIR&quot;</code></pre><h3 id="2-单机安装的配置"><a href="#2-单机安装的配置" class="headerlink" title="2. 单机安装的配置"></a>2. 单机安装的配置</h3><p>进入目录 <code>/usr/local/hadoop/etc/hadoop</code>,找到以下文件</p><ul><li>hadoop-env.sh</li><li>yarn-env.sh</li><li>mapred-env.sh</li></ul><p>均要添加<code>export JAVA_HOME=xxxxx</code></p><p>此时使用，应有hadoop版本信息</p><pre class="line-numbers language-bash"><code class="language-bash">hadoop version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="五、伪分布式安装"><a href="#五、伪分布式安装" class="headerlink" title="五、伪分布式安装"></a>五、伪分布式安装</h2><p>core-site.xml配置</p><pre><code>&lt;configuration&gt;    &lt;property&gt;         &lt;name&gt;fs.defaultFS&lt;/name&gt;         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;         &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;    &lt;/property&gt;  &lt;/configuration&gt;</code></pre><p>hdfs-site.xml配置</p><pre><code>&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;dfs.replication&lt;/name&gt;                &lt;value&gt;1&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;                &lt;value&gt;/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;                &lt;value&gt;/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>mapred-site.xml配置</p><pre><code>&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;                &lt;value&gt;yarn&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>yarn-site.xml配置</p><pre><code>&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;        &lt;property&gt;                 &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;                 &lt;value&gt;mapreduce_shuffle&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;                  &lt;value&gt;localhost&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;yarn.application.classpath&lt;/name&gt;                &lt;value&gt;使用`hadoop classpath`命令查询,将结果放在此处&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>配置完后初始化一下。否则后面会报错没有<code>namenode</code>节点</p><pre class="line-numbers language-bash"><code class="language-bash">hadoop namenode -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>再运行</p><pre class="line-numbers language-bash"><code class="language-bash">start-all.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>即可开启hadoop服务</p><p>如果报错没有<code>start-all.sh</code>命令，即环境变量配置的问题，后面都是如此。</p><p>注意看开启的信息，如果成功输入命令<code>jps</code><br>可得到如下类似结果</p><pre><code>NodeManagerJpsNameNodeSecondaryNameNodeResourceMangerDataNode</code></pre><p>注意是6个</p><p>这个时候可以打开hadoop的web页面 <code>localhost:9870</code></p><p>接下来尝试使用hadoop自带的wordcount来实现单词统计的功能</p><p>创建一个文件<code>test.txt</code>里面内容为<code>hello hadoop my hadoop</code></p><p> 注意以下的test.txt文件路径为我自己的文件路径<br> 依次输入以下命令</p><pre><code>hdfs dfs -mkdir -p /test/input #创建入口hdfs dfs -ls / #查看有哪些文件hdfs dfs -put /home/hadoop/test.txt /test/input #将test.txt放入hdfs dfs -cat /test/input/test.txt  #查看放入的test.txt文件内容yarn jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount /test/input /test/output  #使用wordcounthdfs dfs -cat /test/output/part-r-00000 #查看结果</code></pre><p> hadoop的简单配置到此结束！</p>]]></content>
      
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人小站创建成功！欢迎来访！</title>
      <link href="posts/41794.html"/>
      <url>posts/41794.html</url>
      
        <content type="html"><![CDATA[<p>经过多番摸索，终于在今天创建好了我的个人小站！ 今后它将与我共同成长，一起进步，一起变得更完美！</p><p>我是刘书程，一个前端小白~</p>]]></content>
      
      
      <categories>
          
          <category> 日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
